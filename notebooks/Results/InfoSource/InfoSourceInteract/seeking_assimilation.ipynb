{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('../../../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from computations.insights.opinions import varying_parameters\n",
    "from plotting.basic import *\n",
    "from plotting.summaries import *\n",
    "from matplotlib import pyplot as plt\n",
    "from computations.probabilistic.vectorised import *\n",
    "from society.structure.network import ArtificialNetwork\n",
    "from society.beliefs import Distribution, BeliefDistribution\n",
    "from computations.insights.opinions import mse_seeking_uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.2\n",
    "information_source = (0.6, 0.3)\n",
    "linespace = Distribution(type=\"linespace\", range=(-1,1))\n",
    "unique = Distribution(type=\"unique\", value=sigma)\n",
    "belief_distribution = BeliefDistribution(unique, unique, linespace)\n",
    "network = ArtificialNetwork(1000, \"random_graph\", p=0.01)\n",
    "agent_network = AgentNetwork(belief_distribution, network, agent_type=AnalyticalAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerance = sigma*6\n",
    "update_rule = UpdateRule(evaluation_bias=0.3, assimilation_bias=0, rewire_probability=1, tolerance=tolerance)\n",
    "interactions = Interactions(update_rule, interaction_rate=1, interacting_agents=True,)\n",
    "insights = Insights()\n",
    "simulation = Simulation(10000, insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 of 19|0 of 16:  22%|██▏       | 218/1000 [00:14<00:52, 15.00it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m assimilation_biases \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39m0.01\u001b[39m, \u001b[39m0.2\u001b[39m, \u001b[39m0.01\u001b[39m)\u001b[39m.\u001b[39mround(\u001b[39m2\u001b[39m)\n\u001b[1;32m      2\u001b[0m initial_uncertainties \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39m0.1\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m0.025\u001b[39m)\u001b[39m.\u001b[39mround(\u001b[39m2\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m results \u001b[39m=\u001b[39m mse_assimilation_uncertainty(assimilation_biases, initial_uncertainties, agent_network, simulation, interactions)\n",
      "File \u001b[0;32m~/Desktop/New_Honours_Refactored/src/computations/insights/opinions.py:134\u001b[0m, in \u001b[0;36mmse_assimilation_uncertainty\u001b[0;34m(assimilation_biases, initial_uncertainties, agent_network, simulation, interactions, repetitions)\u001b[0m\n\u001b[1;32m    132\u001b[0m mses \u001b[39m=\u001b[39m []\n\u001b[1;32m    133\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(repetitions):\n\u001b[0;32m--> 134\u001b[0m     simulation\u001b[39m.\u001b[39;49mrun(interactions, agent_network, description\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m of \u001b[39;49m\u001b[39m{\u001b[39;49;00mevaluation_num\u001b[39m}\u001b[39;49;00m\u001b[39m|\u001b[39;49m\u001b[39m{\u001b[39;49;00mj\u001b[39m}\u001b[39;49;00m\u001b[39m of \u001b[39;49m\u001b[39m{\u001b[39;49;00muncertainties_num\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    135\u001b[0m     mses\u001b[39m.\u001b[39mappend(simulation\u001b[39m.\u001b[39minsights\u001b[39m.\u001b[39mmse_evolution[simulation\u001b[39m.\u001b[39miterations])\n\u001b[1;32m    136\u001b[0m heat_map[i][j] \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(mses)\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(mses)\n",
      "File \u001b[0;32m~/Desktop/New_Honours_Refactored/src/simulation/Simulation.py:15\u001b[0m, in \u001b[0;36mSimulation.run\u001b[0;34m(self, interactions, agent_network, description)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m trange(\u001b[39m2\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterations \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m, desc\u001b[39m=\u001b[39mdescription):\n\u001b[1;32m     14\u001b[0m     \u001b[39mfor\u001b[39;00m agent \u001b[39min\u001b[39;00m agent_network\u001b[39m.\u001b[39magents:\n\u001b[0;32m---> 15\u001b[0m         interactions\u001b[39m.\u001b[39;49mupdate(agent_network, agent)\n\u001b[1;32m     16\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minsights\u001b[39m.\u001b[39mupdate_insights(agent_network, interactions, k)\n",
      "File \u001b[0;32m~/Desktop/New_Honours_Refactored/src/updates/Interactions.py:31\u001b[0m, in \u001b[0;36mInteractions.update\u001b[0;34m(self, agent_network, agent)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mif\u001b[39;00m random\u001b[39m.\u001b[39muniform(\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m) \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minteraction_rate:\n\u001b[1;32m     30\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minteracting_agents:\n\u001b[0;32m---> 31\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent_interaction(agent_network, agent)\n\u001b[1;32m     32\u001b[0m \u001b[39melse\u001b[39;00m:    \n\u001b[1;32m     33\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minformation_source:\n",
      "File \u001b[0;32m~/Desktop/New_Honours_Refactored/src/updates/Interactions.py:16\u001b[0m, in \u001b[0;36mInteractions.agent_interaction\u001b[0;34m(self, agent_network, agent)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39magent_interaction\u001b[39m(\u001b[39mself\u001b[39m, agent_network, agent):\n\u001b[1;32m     15\u001b[0m     observed_agent \u001b[39m=\u001b[39m agent_network\u001b[39m.\u001b[39mget_observed_agent(agent)\n\u001b[0;32m---> 16\u001b[0m     agent\u001b[39m.\u001b[39mbelief_old \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39;49mdeepcopy(agent\u001b[39m.\u001b[39;49mbelief)\n\u001b[1;32m     17\u001b[0m     agent\u001b[39m.\u001b[39mbelief \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_rule\u001b[39m.\u001b[39mbelief_update(agent, observed_agent)\n\u001b[1;32m     18\u001b[0m     agent_network\u001b[39m.\u001b[39mrewire_network(agent, observed_agent, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_rule)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/copy.py:128\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    124\u001b[0m     d[PyStringMap] \u001b[39m=\u001b[39m PyStringMap\u001b[39m.\u001b[39mcopy\n\u001b[1;32m    126\u001b[0m \u001b[39mdel\u001b[39;00m d, t\n\u001b[0;32m--> 128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeepcopy\u001b[39m(x, memo\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, _nil\u001b[39m=\u001b[39m[]):\n\u001b[1;32m    129\u001b[0m     \u001b[39m\"\"\"Deep copy operation on arbitrary Python objects.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \n\u001b[1;32m    131\u001b[0m \u001b[39m    See the module's __doc__ string for more info.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     \u001b[39mif\u001b[39;00m memo \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assimilation_biases = np.arange(0.01, 0.2, 0.01).round(2)\n",
    "initial_uncertainties = np.arange(0.1, 0.5, 0.025).round(2)\n",
    "results = mse_seeking_uncertainty(assimilation_biases, initial_uncertainties, agent_network, simulation, interactions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
